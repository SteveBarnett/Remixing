---
layout: page
title: 'Notes from "Intelligence in the Age of Mechanical Reproduction"'
added: 2025-02-04
updated: 2025-02-04
notes: true
---

From [Intelligence in the Age of Mechanical Reproduction by Charles Eisenstein](https://channelmcgilchrist.com/intelligence-in-the-age-of-mechanical-reproduction-by-charles-eisenstein/)

## Gathered notes

...

## Exported highlights

When human beings outsource any physical or cognitive function to other people or to machines, that function may atrophy within themselves. New functions may open up, but at a price. Is the price worth paying? Maybe it is; but let us be aware of the bargain we are entering. 

The invention of cooking led to a decrease in the size and strength of the human jaw muscles. Clothing and indoor heating led to a reduction in physical hardihood.  ...

You may have noticed that when you use GPS for every trip, not only do you not learn how to navigate your area, but you lose some of the general ability to learn any area. The sense of direction, the sense of place, and the ability to remember a sequence of landmarks atrophies.

However, matters are not so simple as a progressive degradation of intelligence as we outsource it to technology. As the example of the written word suggests, the transfer of cognitive functions to external media can unlock new realms of intellectual development and expression, as well as new forms of social organization and new psychologies.

### The ubiquitous image

In oral cultures, the transmission of information always happens in the context of a relationship. What is spoken is inseparable from who is speaking. 

A book on the other hand remains the same through time and space, lending to its contents the appearance of objectivity, abstracting knowledge from the knower, and making the experience of understanding a private, rather than a relational or communal, affair.

A perspective painting is “realistic” only if one assumes the primacy of an individual observer.

It is of more than just ironic significance that the very technologies—printing, photography, audio, and film—that promised a faithful record of reality cleansed of subjectivity have evolved to be instruments of the precise opposite. A book (that is, its electronic equivalent) no longer necessarily “remains the same through time and space,” but can be altered at the whim of whoever controls the digital technology.

The great photographers, as the great painters, see with a different eye, and show us what we would ordinarily not notice, while propagandists show us what those in power want us to see.

The convergence of recording technology with generative technology requires again that we know and trust the source of words, images, etc. Truth cannot exist outside of relationship.

Walter Benjamin argues that mechanically reproduced art (e.g. photographs, film) necessarily lacks something he called the “aura” of an artwork, a function of its uniqueness and relationality. Unlike a physical painting, which is embedded in a history of ownership, occupies a single location, and ages with time, reproduced images lose their attachment to their original context. 

The commodity object is both detached from its origins and stripped of its uniqueness.

### Deskilling the mind 

When machines do the work of imagining for us, and the work of understanding a text, posing an argument, or writing a business plan, we risk succumbing to a passive conditioned helplessness disconnected from our creative authorship. We are left defenseless against the authoritarian agendas that AI and total information awareness make possible. Indeed, we may come to welcome them.

The parallel between how my brain works when it is on autopilot and how generative AI works is uncanny. The orthodoxy and homogenization of cognitive output—a kind of dementia—that I have described actually plagues AI as well

The AI agent replaces what one might call an organ of the brain, a kind of digestive organ. Organs that we don’t use atrophy like the eyes of a cave-dwelling fish.

You get the bones but not the flesh or the blood. For some purposes, it is indeed only the skeleton that is relevant. But what will happen when, more and more, we see just the bones?

that summary won’t include details that pass beneath the threshold of notice yet contribute to my impression of the conversation. For example, which of the people jump quickly into a pause to speak, and which hold back, and for how long, and how eagerly they speak, and the extent to which they build on the previous person, and the cadence of their speech, the emotional tone of their voice, and the expressions on their face.

A summary doesn’t only distill information, it translates it from one form to another. It can extract only that sort of information that is extractable. Information that is inescapably contextual can only be transmitted in kind.

The whole process of summary is inherently biased towards certain kinds of information, which in turn correspond to a mode of cognition that thinks in bullet points; that divides information into discrete bits; that seeks to distill, to purify, to extract, to reduce; and that grows oblivious to all that resists such reduction.

### Three levels of orthodoxy 

AI draws on the database of all recorded human knowledge. All recorded human knowledge. That sentence alone already points to its potential and its peril.

it deepens our entrenchment in the kind of knowledge that has been recorded and can be recorded, along with, more insidiously, the ways of thinking that correspond to that kind of knowledge.

AI, then, is infused with an insidious orthodoxy. In fact its orthodoxy operates on three levels.

The most superficial is the deliberate bias introduced through the LLM training and fine-tuning to favor certain political beliefs, scientific paradigms, medical orthodoxies, and so forth.

Second is the bias inherent in the training set itself, in which a few paradigms of science, history, etc. predominate.

Not only does outsourcing inquiry, research, writing, summarization, teaching, and understanding to AI risk the atrophy of those capabilities within ourselves, it also erodes our ability to resist the orthodoxies that it entrenches.

The third level of orthodoxy is more subtle. The kinds of knowledge that are conventional are part of a civilizational mythology and a way of thinking. 

AI text generation tends to mirror the rational discourse of the educated classes of society. This kind of language conforms—not just in content but also in structure—to the above-mentioned “Wikipedia version of reality.”

The probabilistic function that generates “what comes next” given an input is necessarily orthodox because it represents the patterns that prevail in the training data. It cannot be eliminated. It is inherent to the way the technology works. 

### The homogenization of thought

The entrenchment of orthodoxies exemplifies a more general danger of artificial intelligence, another kind of collective dementia: the homogenization of thought.

The dissociation of symbol from reality was well underway long before AI. Of all the symbolic systems that have spun off into fantasy, the most obvious is money. The wealth it supposedly measures has become so detached from nature and collective human wellbeing that its pursuit threatens to destroy both.

The point is not that we should never use metrics, symbols, or categories., but that we must connect them repeatedly to the reality they represent, or we will be lost.

The homogenization and simplification of landscapes, of ecosystems, of thought, of culture, and of language is to be expected as we migrate from the infinity of the world of the senses to a finite set of symbols. That’s what has happened to language in the digital age, as metaphors and figures of speech dissociate from physical experiences and come to mean more and more the same thing.

The mind stays intelligent when it can renew its symbols and metaphors by connecting to their material, sensory source. 

We can use a variety of clever words and phrases but without material experiences to draw on, their nuances fade.

The homogeneity stems from a narrowing of the band of output, the elimination of the probabilistic outliers. The original probability distribution, drawing on human input, is quite broad, but narrows with repeated iterations when there is no continuing input of novelty. 

### The original alignment problem

As with AI, orthodoxies filter out and distort the very information that would overthrow them, and the society loses its mooring in reality. 

Disaster ensues when we become detached from the reality beneath our symbols. 

 In fact, the “A” should probably stand for “amplified,” not “artificial.” AI certainly does amplify our intelligence, but it also amplifies our stupidity, our insanity, our disconnection, and the consequences of our errors. We must understand it in this way if we are to use it well.

 It is not a mere technical problem. It is the latest iteration of the original alignment problem of symbolic culture that every society has grappled with. AI merely brings to it a new level of urgency. 
